{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing Required Modules<h3/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/skylab_instagram_datathon_dataset.csv\", sep=\";\")\n",
    "df_original = df.copy(deep=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Removing columns \"period\", \"calculation_type\" <h3\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing \"period\", \"calculation_type\" since the number of followers, likes,... are independent of these cathegories(Comment out after first run)\n",
    "df = df_original.copy(deep=True) \n",
    "df.drop(columns=[\"period\", \"calculation_type\", \"domicile_country_name\",\"primary_exchange_name\", \"compset\", \"legal_entity_name\",\"ultimate_parent_legal_entity_name\"], inplace=True)\n",
    "#df.drop(columns=[\"period\", \"calculation_type\", \"domicile_country_name\",\"primary_exchange_name\", \"compset\"], inplace=True)\n",
    "\n",
    "df.sort_values(by=[\"period_end_date\"], inplace=True, ascending=False)\n",
    "display(df.head())\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumption: A brand will not be in different compset_groups over time!\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "#now after removing duplicte rows, we can remove compset_group column\n",
    "df.drop(columns=[\"compset_group\"], inplace=True)\n",
    "\n",
    "df.sort_values(by=[\"business_entity_doing_business_as_name\", \"period_end_date\"], inplace=True, ascending=False)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "display(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #needed to evaluate \"All Brands\" brand data\n",
    "\n",
    "# df_tests = df[df[\"business_entity_doing_business_as_name\"] ==\"All Brands\"]\n",
    "# df_tests = df_tests[df_tests[\"compset_group\"] ==\"Luxury & Premium & Mainstream\"]\n",
    "# df_tests.shape\n",
    "\n",
    "# #get counts of unique values in each column\n",
    "# for col in df_tests.columns:\n",
    "#     print(\"Sum per column: \", df_tests[col].value_counts().sum())\n",
    "\n",
    "#     print(col)\n",
    "#     display(df_tests[col].value_counts())\n",
    "#     print(len(df_tests[col].value_counts()))\n",
    "#     print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.pivot(index =\"period_end_date\", \n",
    "        #columns= [\"compset_group\", \"business_entity_doing_business_as_name\", \"legal_entity_name\", \"ultimate_parent_legal_entity_name\"],\n",
    "        #values=[\"followers\", \"pictures\", \"videos\", \"comments\", \"likes\"]).head()\n",
    "\n",
    "#check for nan values in the dataset\n",
    "nan_rows = df.isna().sum()\n",
    "display(nan_rows)\n",
    "\n",
    "\n",
    "#get rows with nan values\n",
    "df[df.isna().any(axis=1)]\n",
    "\n",
    "\n",
    "# columns = df.columns\n",
    "# print(columns)\n",
    "# df_sum = 0\n",
    "\n",
    "# for i in columns:\n",
    "    \n",
    "#     print(\"\\n\")\n",
    "#     print(\"-----------------------------------------------------------------------------\")\n",
    "#     print(i, \"--> has length:\", len(df[i].unique()))\n",
    "#     df_i = df[i].value_counts().reset_index()\n",
    "#     df_i.columns = [i, \"count\"]\n",
    "#     display(df_i)\n",
    "#     df_sum = df_i[\"count\"].sum()\n",
    "#     print(\"Sum of count:\", df_sum)\n",
    "#     df_sum = 0\n",
    "#     print(\"-----------------------------------------------------------------------------\")\n",
    "#     print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Using Timedelta instead of Absolute datetime and ordering by datetime <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking timedelta from first available end date instead of absolute date (COMMENT OUT AFTER FIRST RUN)\n",
    "#df['period_end_date'] = pd.to_datetime(df['period_end_date'])\n",
    "#min_date = df['period_end_date'].min()\n",
    "#df['period_end_date'] = df['period_end_date'] - min_date\n",
    "#order by period_end_date\n",
    "df.sort_values(by=[\"business_entity_doing_business_as_name\", \"period_end_date\"], inplace=True, ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> where do we have missing values?<h3\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in df.columns:\n",
    "    if df[df[name].isnull()].shape[0] > 0:\n",
    "        print(\"number of missing values for \",name, \": \",df[df[name].isnull()].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Investigation of Domicile Country Name<h3\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMMENT OUT AFTER FIRST RUN\n",
    "#nan_domicile = df[df['domicile_country_name'].isnull()]\n",
    "#nan_domicile[\"business_entity_doing_business_as_name\"].unique().size\n",
    "#check if brand has non-null domicile for each brand\n",
    "#for brand in nan_domicile[\"business_entity_doing_business_as_name\"].unique():\n",
    "    #known_brands = []\n",
    "    #check if brand has non-null domicile\n",
    "    #if df[df[\"business_entity_doing_business_as_name\"] == brand][\"domicile_country_name\"].notnull().any():\n",
    "        #known_brands.append(brand)\n",
    "        #print(brand)\n",
    "#the result is empty, so we can't get the domicile from another row\n",
    "#remove domicile_country_name column\n",
    "#df.drop(columns=[\"domicile_country_name\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathegories = [\"followers\", \"likes\", \"comments\", \"videos\", \"pictures\"]\n",
    "for name in cathegories:\n",
    "    print(\"number of missing values for \",name, \": \",df[df[name].isnull()].shape[0] + df[df[name] == 0].shape[0])\n",
    "    print(\"number of zeros for \",name, \": \",df[df[name] == 0].shape[0])\n",
    "    #ratio of zeros + nan to total\n",
    "    print(\"ratio of zeros + nan to total for \",name, \": \",(df[df[name].isnull()].shape[0] + df[df[name] == 0].shape[0])/df.shape[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill nan with zeros\n",
    "for name in cathegories:\n",
    "    df[name].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brands_missing_values = pd.DataFrame(columns=[\"brand\", \"cathegory\", \"ratio\"])\n",
    "\n",
    "# for name in df[\"business_entity_doing_business_as_name\"].unique():\n",
    "#     for cathegory in cathegories:\n",
    "#         nr_missing_values = df[(df[\"business_entity_doing_business_as_name\"] == name) & (df[cathegory].isnull() | (df[cathegory] == 0))].shape[0]\n",
    "#         ratio = nr_missing_values / df[df[\"business_entity_doing_business_as_name\"] == name].shape[0]\n",
    "#         if ratio > 0.3:\n",
    "#             brands_missing_values.loc[len(brands_missing_values.index)] = [name, cathegory, ratio]\n",
    "#             #print(\"brand: \",name, \" cathegory: \",cathegory, \" ratio: \",ratio)\n",
    "#brands_missing_values.to_csv(\"data/brands_missing_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling missing values with the mean of the brand \n",
    "\n",
    "\n",
    "# for name in df[\"business_entity_doing_business_as_name\"].unique():\n",
    "#     for cathegory in cathegories:\n",
    "#         #if there are zeros or nan values for a brand, fill them with the mean of the brand\n",
    "#         if df[(df[\"business_entity_doing_business_as_name\"] == name) & (df[cathegory].isnull() | (df[cathegory] == 0))].shape[0] > 0:\n",
    "#             mean = df[df[\"business_entity_doing_business_as_name\"] == name][cathegory].mean()\n",
    "#             df.loc[(df[\"business_entity_doing_business_as_name\"] == name) & (df[cathegory].isnull() | (df[cathegory] == 0)), cathegory] = mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.pivot(index =\"period_end_date\", \n",
    "        #columns= [\"compset_group\", \"business_entity_doing_business_as_name\", \"legal_entity_name\", \"ultimate_parent_legal_entity_name\"],\n",
    "        #values=[\"followers\", \"pictures\", \"videos\", \"comments\", \"likes\"]).head()\n",
    "\n",
    "#check for nan values in the dataset\n",
    "nan_rows = df.isna().sum()\n",
    "display(nan_rows)\n",
    "\n",
    "\n",
    "#get rows with nan values\n",
    "df[df.isna().any(axis=1)]\n",
    "\n",
    "\n",
    "columns = df.columns\n",
    "print(columns)\n",
    "df_sum = 0\n",
    "\n",
    "for i in columns:\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"-----------------------------------------------------------------------------\")\n",
    "    print(i, \"--> has length:\", len(df[i].unique()))\n",
    "    df_i = df[i].value_counts().reset_index()\n",
    "    df_i.columns = [i, \"count\"]\n",
    "    display(df_i)\n",
    "    df_sum = df_i[\"count\"].sum()\n",
    "    print(\"Sum of count:\", df_sum)\n",
    "    df_sum = 0\n",
    "    print(\"-----------------------------------------------------------------------------\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(10))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.tail(10))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the cleaned data\n",
    "df.to_csv(\"../data/cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
